#!/usr/bin/env python

import rospy
import cv2
import numpy as np
import time

from crane_vision.transformations import trf
from crane_vision.camera import CameraArray
from crane_vision.vision import find_sphere_centers, find_line
from crane_vision.ekf import ekf


# Camera calibration matrices
K0 = np.array([[937, 0, 637.21],
               [0, 937, 381.54],
               [0, 0,   1.0]])

K1 = np.array([[941, 0, 637.21],
               [0, 941, 349.9],
               [0, 0,   1.0]])

K2 = np.array([[942, 0, 623.66],
               [0, 942, 345.69],
               [0, 0,   1.0]])

# Translation vectors between cameras
t_11 = np.array([0, 0, 0])
t_21 = -np.array([233.8, 0, 0])
t_31 = -np.array([467, 0, 0])
PII = np.eye(3, 4)

# Camera matrices
P0 = np.dot(np.dot(K0, PII), trf(np.eye(3), t_11))
P1 = np.dot(np.dot(K1, PII), trf(np.eye(3), t_21))
P2 = np.dot(np.dot(K2, PII), trf(np.eye(3), t_31))


def main():
    rospy.init_node('crane_vision_node')

    cams = CameraArray([0, 1, 2], (1280, 720))

    center01 = (0, 0)
    center02 = (0, 0)
    center11 = (0, 0)
    center12 = (0, 0)
    center21 = (0, 0)
    center22 = (0, 0)

    hat_Pkm1 = np.diag([0, 0, 0, 0, 0, 0])
    hat_thetakm1 = np.array([0, 0, 0, 0, 2.5*np.pi/180, -1.7*np.pi/180])

    q1 = 0.2  # Debug
    ddx = 0.1  # Debug
    ddy = 0.1  # Debug
    Lhat = 0.5  # Debug
    dt = 0.1  # Debug

    start_time = time.time()
    current_time = start_time
    previous_time = current_time

    try:
        while not rospy.is_shutdown():
            frames = cams.read()
            if frames is not None:
                frame1, frame2, frame3 = frames
                # Find pixels that corresponds to the spheres
                center01, center02 = find_sphere_centers(
                    frame1, center01, center02)
                center11, center12 = find_sphere_centers(
                    frame2, center11, center12)
                center21, center22 = find_sphere_centers(
                    frame3, center21, center22)

                # Find direction vector of a line through the spheres,
                # given in camera coordinates
                Lc0 = find_line(center01, center02,
                                center11, center12,
                                center21, center22,
                                P0, P1, P2)

                # Find direction vector of a line through the spheres,
                # given in inertial coordinates
                Lvec = np.dot(np.array([[-np.cos(q1), 0, np.sin(q1)],
                                        [np.sin(q1), 0, np.cos(q1)],
                                        [0, 1.0, 0]]), Lc0)
                if np.linalg.norm(Lvec) > 0.00001:
                    Lvec = Lvec / np.linalg.norm(Lvec)

                current_time = time.time()
                dt = current_time - previous_time
                previous_time = current_time

                rospy.loginfo(1.0 / dt)

                hat_thetak, hat_Pk, zk = ekf(Lvec,
                                             np.array([ddx, ddy]),
                                             hat_Pkm1,
                                             hat_thetakm1,
                                             q1,
                                             Lhat,
                                             dt)

    except rospy.ROSInterruptException:
        pass


if __name__ == "__main__":
    main()
