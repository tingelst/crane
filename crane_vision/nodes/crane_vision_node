#!/usr/bin/env python

import rospy
import tf

import cv2
import numpy as np

from crane_vision.vision import DLT, FindCenter, FindLine
from crane_vision.transformations import TransMat
from crane_vision.ekf import EKF


class Camera(object):
    def __init__(self, device):
        self._cam = cv2.VideoCapture(device)

    def downscale_image(self, size):
        x, y = size
        self._cam.set(3, x)
        self._cam.set(4, y)


class PayloadOscillationEstimator(object):

    def __init__(self):
        # Initialize cameras and downsize image capture
        self._vs1 = cv2.VideoCapture(0)
        self._vs1.set(3, 1280)
        self._vs1.set(4, 720)
        self._vs2 = cv2.VideoCapture(2)
        self._vs2.set(3, 1280)
        self._vs2.set(4, 720)
        self._vs3 = cv2.VideoCapture(1)
        self._vs3.set(3, 1280)
        self._vs3.set(4, 720)

        # Camera calibration matrices
        K0 = np.array([[937, 0, 637.21],
                       [0, 937, 381.54],
                       [0, 0,   1.0]])

        K1 = np.array([[941, 0, 637.21],
                       [0, 941, 349.9],
                       [0, 0,   1.0]])

        K2 = np.array([[942, 0, 623.66],
                       [0, 942, 345.69],
                       [0, 0,   1.0]])

        # Translation vectors between cameras
        t_11 = -np.array([0, 0, 0])
        t_21 = -np.array([233.8, 0, 0])
        t_31 = -np.array([467, 0, 0])
        PII = np.eye(3, 4)

        # Camera matrices
        self._P0 = np.dot(np.dot(K0, PII), TransMat(np.eye(3), t_11))
        self._P1 = np.dot(np.dot(K1, PII), TransMat(np.eye(3), t_21))
        self._P2 = np.dot(np.dot(K2, PII), TransMat(np.eye(3), t_31))

    def __del__(self):
        self._vs1.release()
        self._vs2.release()
        self._vs3.release()

    def _capture(self):
        '''Capture images from the cameras'''
        _, frame1 = self._vs1.read()
        _, frame2 = self._vs2.read()
        _, frame3 = self._vs3.read()

        if frame1 is None:
            return None
        elif frame2 is None:
            return None
        elif frame3 is None:
            return None
        else:
            return (frame1, frame2, frame3)

    def _init_cameras(self):
        '''Spin until all three cameras are initialized'''
        while self._capture() is None:
            pass

    def run(self):

        # Init pixels and states for EKF
        center01 = (0, 0)
        center02 = (0, 0)
        center11 = (0, 0)
        center12 = (0, 0)
        center21 = (0, 0)
        center22 = (0, 0)
        hat_Pkm1 = np.diag([0, 0, 0, 0, 0, 0])
        hat_thetakm1 = np.array(
            [0, 0, 0, 0, 2.5*np.pi/180, -1.7*np.pi/180])

        try:
            while not rospy.is_shutdown():
                # Capture images
                frame1, frame2, frame3 = self._capture()

                # Find pixels that corresponds to the spheres
                center01, center02 = FindCenter(frame1, center01, center02)
                center11, center12 = FindCenter(frame2, center11, center12)
                center21, center22 = FindCenter(frame3, center21, center22)

                # Find direction vector of a line through the spheres, given in camera coordinates
                Lc0 = FindLine(center01, center02, center11,
                               center12, center21, center22,
                               self._P0, self._P1, self._P2)

                # find direction vector of a line through the spheres, given in inertial coordinates
                Lvec = np.dot(np.array([[-np.cos(Obj.q1), 0, np.sin(Obj.q1)],
                                        [np.sin(Obj.q1), 0, np.cos(Obj.q1)],
                                        [0, 1,       0]]), Lc0)

                if np.linalg.norm(Lvec) > 0.00001:
                    Lvec = Lvec/np.linalg.norm(Lvec)

                # Extended Kalman Filter
                hat_thetak, hat_Pk, zk = EKF(Lvec,
                                             np.array([Obj.ddx, Obj.ddy]),
                                             hat_Pkm1,
                                             hat_thetakm1,
                                             Obj.q1,
                                             Obj.Lhat,
                                             current_time()-tk)

                # Collect estimated payload oscillation angles and rates, bias of payload oscillation angle, and measurement of payload oscillation angle
                # Obj.senddata = np.array([hat_thetak[0], hat_thetak[1], hat_thetak[2],
                #                          hat_thetak[3], hat_thetak[4], hat_thetak[5], zk[0], zk[1]])
                msgToMatlab.put(hat_thetak)
                Obj.senddata
                hat_thetakm1 = hat_thetak
                hat_Pkm1 = hat_Pk
                StoredData.update(zk, hat_thetak, start, tk)
                tk = current_time()

        except rospy.ROSInterruptException:
            pass


def main():
    pass


if __name__ == "__main__":
    main()
